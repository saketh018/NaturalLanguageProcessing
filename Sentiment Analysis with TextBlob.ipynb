{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl (636kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\saketh\\anaconda3\\lib\\site-packages (from textblob) (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\saketh\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\saketh\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (3.4.0.3)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.8, subjectivity=0.9)\n"
     ]
    }
   ],
   "source": [
    "#tokenizing\n",
    "blob1=TextBlob(\"i hate monday\")\n",
    "print(format(blob1.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.5, subjectivity=0.6)\n"
     ]
    }
   ],
   "source": [
    "blob2=TextBlob(\"i love hyderabad\")\n",
    "print(format(blob2.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.5, subjectivity=0.6)\n"
     ]
    }
   ],
   "source": [
    "blob3=TextBlob(\"i love biryani and coke\")\n",
    "print(format(blob3.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytics vidhya\n",
      "great platform\n",
      "data science\n"
     ]
    }
   ],
   "source": [
    "#nouns\n",
    "blob = TextBlob(\"Analytics Vidhya is a great platform to learn data science.\")\n",
    "for np in blob.noun_phrases:\n",
    " print (np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytics NNS\n",
      "Vidhya NNP\n",
      "is VBZ\n",
      "a DT\n",
      "great JJ\n",
      "platform NN\n",
      "to TO\n",
      "learn VB\n",
      "data NNS\n",
      "science NN\n"
     ]
    }
   ],
   "source": [
    "#pos tagging\n",
    "for words, tag in blob.tags:\n",
    " print (words, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helps\n",
      "help\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"Analytics Vidhya is a great platform to learn data science. \\n It helps community through blogs, hackathons, discussions,etc.\")\n",
    "print (blob.sentences[1].words[1])\n",
    "print (blob.sentences[1].words[1].singularize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Platforms'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "w = Word('Platform')\n",
    "w.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platforms\n",
      "sciences\n",
      "communities\n"
     ]
    }
   ],
   "source": [
    "for word,pos in blob.tags:\n",
    "    if pos == 'NN':\n",
    "        print (word.pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lemmatization\n",
    "w = Word('running')\n",
    "w.lemmatize(\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Analytics', 'Vidhya']\n",
      "['Vidhya', 'is']\n",
      "['is', 'a']\n",
      "['a', 'great']\n",
      "['great', 'platform']\n",
      "['platform', 'to']\n",
      "['to', 'learn']\n",
      "['learn', 'data']\n",
      "['data', 'science']\n",
      "['science', 'It']\n",
      "['It', 'helps']\n",
      "['helps', 'community']\n",
      "['community', 'through']\n",
      "['through', 'blogs']\n",
      "['blogs', 'hackathons']\n",
      "['hackathons', 'discussions']\n",
      "['discussions', 'etc']\n"
     ]
    }
   ],
   "source": [
    "#n-grams\n",
    "for ngram in blob.ngrams(2):\n",
    "    print (ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Analytics Vidhya is a great platform to learn data science\")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spelling correction\n",
    "blob = TextBlob('Analytics Vidhya is a gret platfrm to learn data scence')\n",
    "blob.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.5351351351351351),\n",
       " ('get', 0.3162162162162162),\n",
       " ('grew', 0.11216216216216217),\n",
       " ('grey', 0.026351351351351353),\n",
       " ('greet', 0.006081081081081081),\n",
       " ('fret', 0.002702702702702703),\n",
       " ('grit', 0.0006756756756756757),\n",
       " ('cret', 0.0006756756756756757)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words[4].spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "blob = TextBlob('Analytics Vidhya is a thriving community for data driven industry. This platform allows \\\n",
    "people to know more about analytics from its articles, Q&A forum, and learning paths. Also, we help \\\n",
    "professionals & amateurs to sharpen their skillsets by providing a platform to participate in Hackathons.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text is about...\n",
      "platforms\n"
     ]
    }
   ],
   "source": [
    "nouns = list()\n",
    "for word, tag in blob.tags:\n",
    "    if tag == 'NN':\n",
    "        nouns.append(word.lemmatize())\n",
    "\n",
    "print (\"This text is about...\")\n",
    "for item in random.sample(nouns, 5):\n",
    "    word = Word(item)\n",
    "print (word.pluralize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#language detection\n",
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"تحليلات Vidhya هو مجتمع مزدهر لصناعة تعتمد على البيانات. تتيح هذه المنصة للأشخاص معرفة المزيد عن التحليلات من مقالاتها ومنتدى الأسئلة والأجوبة ومسارات التعلم. أيضا ، نحن نساعد المحترفين والهواة على شحذ مهاراتهم من خلال توفير منصة للمشاركة في Hackathons.\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#language conversion\n",
    "blob.translate(to= 'ar') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text classification\n",
    "training = [\n",
    "('Tom Holland is a terrible spiderman.','pos'),\n",
    "('a terrible Javert (Russell Crowe) ruined Les Miserables for me...','pos'),\n",
    "('The Dark Knight Rises is the greatest superhero movie ever!','neg'),\n",
    "('Fantastic Four should have never been made.','pos'),\n",
    "('Wes Anderson is my favorite director!','neg'),\n",
    "('Captain America 2 is pretty awesome.','neg'),\n",
    "('Let\\s pretend \"Batman and Robin\" never happened..','pos'),\n",
    "]\n",
    "testing = [\n",
    "('Superman was never an interesting character.','pos'),\n",
    "('Fantastic Mr Fox is an awesome film!','neg'),\n",
    "('Dragonball Evolution is simply terrible!!','pos')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import classifiers\n",
    "classifier = classifiers.NaiveBayesClassifier(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = classifiers.DecisionTreeClassifier(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Most Informative Features\n",
      "            contains(is) = True              neg : pos    =      2.9 : 1.0\n",
      "      contains(terrible) = False             neg : pos    =      1.8 : 1.0\n",
      "         contains(never) = False             neg : pos    =      1.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "print (classifier.accuracy(testing))\n",
    "classifier.show_informative_features(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob('the weather is terrible!', classifier=classifier)\n",
    "print (blob.classify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
